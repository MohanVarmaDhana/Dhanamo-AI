{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohanVarmaDhana/Dhanamo-AI/blob/main/Experimentation/Basic_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12M8aJ7k3J6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "371YdCnvnKy0"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \"langchain[google-genai]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "9lwzZKaR0crB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.environ.get('GOOGLE_API_KEY'):\n",
        "  os.environ['GOOGLE_API_KEY'] = getpass.getpass('Enter Gemini Key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOiNYlMJ0cn7",
        "outputId": "b2953202-cc81-4f33-fb51-cb455a963438"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Gemini Key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "id": "yp0mg2rT0chF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage('Translate the following message to Telugu'),\n",
        "    HumanMessage('Hi!')\n",
        "]"
      ],
      "metadata": {
        "id": "nFadrldG2YYY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yGa-3YM0cWs",
        "outputId": "4da1c214-adb6-4dbd-df74-74422cb17a1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='హాయ్!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-8bd7d553-728e-4299-ab1b-4ce7082d45e7-0', usage_metadata={'input_tokens': 8, 'output_tokens': 5, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_template = \"Translate this text into {language}\"\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_template),(\"user\", \"{text}\")\n",
        "])"
      ],
      "metadata": {
        "id": "fYyYfqb7BREb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.invoke({\"language\": \"telugu\", \"text\": 'hello'})"
      ],
      "metadata": {
        "id": "I6LN4hvBBQx-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eO7y0MjBQfv",
        "outputId": "82d28e59-1dc9-4d5b-9068-739d4c3bf8a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='\"Hello\" అనే పదాన్ని తెలుగులో చాలా రకాలుగా చెప్పవచ్చు. సందర్భాన్ని బట్టి వీటిలో ఏదైనా ఉపయోగించవచ్చు:\\n\\n*   **నమస్కారం** (Namaskaram): ఇది చాలా మర్యాదగా పలకరించే పద్ధతి.\\n*   **నమస్తే** (Namaste): ఇది కూడా సాధారణంగా ఉపయోగించే పలకరింపు.\\n*   **బాగున్నారా?** (Bagunnara?): ఇది \"How are you?\" అని అడగడానికి సమానం.\\n*   **ఏంటి విశేషాలు?** (Enti visheshalu?): ఇది \"What\\'s up?\" అని అడగడానికి సమానం.\\n\\nకాబట్టి, మీరు ఎవరినైనా పలకరించడానికి \"నమస్కారం\" లేదా \"నమస్తే\" ఉపయోగించవచ్చు.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-fda6706e-150d-4051-90c1-579d8eec0af0-0', usage_metadata={'input_tokens': 9, 'output_tokens': 252, 'total_tokens': 261, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Chatbot with memory"
      ],
      "metadata": {
        "id": "A14XIEAoBQIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationSummaryBufferMemory"
      ],
      "metadata": {
        "id": "k-1V-K6NBPcu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "## Defining model\n",
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
        "\n",
        "## Defining memory\n",
        "memory = ConversationSummaryBufferMemory(\n",
        "    llm=model,\n",
        "    max_token_limit=1000,\n",
        "    input_key=\"input\"\n",
        ")\n",
        "\n",
        "## Defining Conversational model\n",
        "convModel = ConversationChain(llm = model, memory=memory)"
      ],
      "metadata": {
        "id": "c4LgM8rt11Gh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convModel.predict(input = \"Hi I am Mohan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "CsjK2q5E11Vi",
        "outputId": "bf008a62-9986-45b3-903f-4e8de5bd0b39"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Mohan! It's a pleasure to meet you. I'm excited to chat with you today. I'm an AI assistant, built using a large language model. My responses are generated based on the vast dataset I was trained on, which includes text and code from a variety of publicly available sources. I can try my hand at many different kinds of tasks, like summarizing text, translating languages, writing different kinds of creative content, and answering your questions in an informative way. So, what's on your mind? I'm ready to help if I can!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convModel.predict(input = \"What is my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FmmAksyZ11fs",
        "outputId": "794e0b54-72b4-44b1-a01d-404b575e8ffa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As an AI, I have no memory of past conversations. Therefore, I do not know what your name is. You just told me your name is Mohan. Is that correct?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convModel.predict(input = \"Yes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dJ12uKEy122L",
        "outputId": "c556dbb7-733a-457f-e105-7284a84dcb1f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Great to know, Mohan! So, now I know your name. Is there anything I can help you with today, Mohan? Perhaps you have a question you'd like me to answer, or a task you'd like me to perform? I'm ready when you are!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory"
      ],
      "metadata": {
        "id": "NYfMrqayNWE-",
        "outputId": "e6c9df1f-86cf-498b-c984-422eb5c75f6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationSummaryBufferMemory(llm=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7bc14e70b190>, default_metadata=()), chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi I am Mohan', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Mohan! It's a pleasure to meet you. I'm excited to chat with you today. I'm an AI assistant, built using a large language model. My responses are generated based on the vast dataset I was trained on, which includes text and code from a variety of publicly available sources. I can try my hand at many different kinds of tasks, like summarizing text, translating languages, writing different kinds of creative content, and answering your questions in an informative way. So, what's on your mind? I'm ready to help if I can!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='As an AI, I have no memory of past conversations. Therefore, I do not know what your name is. You just told me your name is Mohan. Is that correct?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Yes', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Great to know, Mohan! So, now I know your name. Is there anything I can help you with today, Mohan? Perhaps you have a question you'd like me to answer, or a task you'd like me to perform? I'm ready when you are!\", additional_kwargs={}, response_metadata={})]), input_key='input', max_token_limit=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}